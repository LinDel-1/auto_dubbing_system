{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16533352-1163-4952-bc72-eb45691c32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c60455d6-01c2-4233-b999-224c1889820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lindel/diploma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2512e00-6786-4c82-8db5-e567167d53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport utils.audio_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e7d1d3-1a78-4db9-a888-3d9136c75212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import librosa\n",
    "import select\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.decomposition import FastICA\n",
    "from tqdm import trange\n",
    "from IPython.display import Audio\n",
    "import subprocess\n",
    "from typing import Optional, Union, Dict, Tuple, IO\n",
    "\n",
    "\n",
    "from utils.audio_funcs import audioread, audiowrite, snr_mixer, audio_normalization, align_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7303b55a-182e-458a-8fa4-b837de9ebdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lindel/diploma/signal_noise'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASEPATH = os.getcwd()\n",
    "BASEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a926cfb-f13d-4fd3-a30e-6a6c778d61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechNoiseDataset:\n",
    "    def __init__(self, speech_root, noise_root, sample_rate=48000):\n",
    "        self.noise_root = noise_root\n",
    "        self.speech_root = speech_root\n",
    "        self.len_speech_dir = self.__get_len_dir(self.speech_root)\n",
    "        self.len_noise_dir = self.__get_len_dir(self.noise_root)\n",
    "        self.signal_noise = {}\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= self.len_speech_dir:\n",
    "            raise IndexError('Index out of range')\n",
    "\n",
    "        if index in self.signal_noise:\n",
    "            noise_idx = self.signal_noise.get(index)\n",
    "        else:\n",
    "            # getting random noise\n",
    "            noise_idx = np.random.randint(0, self.len_noise_dir)\n",
    "            self.signal_noise.update({index: noise_idx})\n",
    "\n",
    "        # reading noise wav by index\n",
    "        rand_noise_path = f'{self.noise_root}/noise_{noise_idx}.wav'\n",
    "        noise, _ = audioread(rand_noise_path, sr=self.sample_rate)\n",
    "\n",
    "        # reading speech wav by index\n",
    "        speech_path = f'{self.speech_root}/speech_{index}.wav'\n",
    "        speech, sr = audioread(speech_path, sr=self.sample_rate)    \n",
    "            \n",
    "        return speech, noise, sr\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len_speech_dir\n",
    "\n",
    "    def __get_len_dir(self, dir_path):\n",
    "        return len(\n",
    "            [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f879b-3ad4-47e8-aedd-e32dc0f5ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sdr_metric(clean_signal, splitted_signal):\n",
    "    # Calculate the power of clean signal\n",
    "    power_clean = np.mean(np.square(clean_signal))\n",
    "\n",
    "    # Calculate the power of noise-removed signal\n",
    "    power_residual = np.mean(np.square(clean_signal - splitted_signal))\n",
    "\n",
    "    # Calculate SDR in dB\n",
    "    sdr_db = 10 * np.log10(power_clean / power_residual)\n",
    "\n",
    "    return sdr_db\n",
    "\n",
    "\n",
    "def calculate_r2_metric(clean_signal, splitted_signal):\n",
    "    # Compute mean of the clean signal\n",
    "    mean_clean = np.mean(clean_signal)\n",
    "\n",
    "    # Compute sum of squares of the residuals (SSR)\n",
    "    ssr = np.sum(np.square(clean_signal - splitted_signal))\n",
    "    \n",
    "    # Calculate TSS as the total sum of squares of the clean signal\n",
    "    tss = ssr + np.sum(np.square(splitted_signal - mean_clean))\n",
    "    \n",
    "    # Calculate R2\n",
    "    r2 = 1 - (ssr / tss)\n",
    "\n",
    "    return r2\n",
    "\n",
    "def rmse_metric(clean_signal, splitted_signal):\n",
    "    return mean_squared_error(clean_signal, splitted_signal, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b25eb3-ee7d-4ead-a6ee-9f3bf7c2a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metrics(clean_speech_signal, splitted_speech_signal, clean_noise_signal=None, splitted_noise_signal=None):\n",
    "    metric_functions = {'sdr': calculate_sdr_metric, 'r2': calculate_r2_metric, 'rmse': rmse_metric}\n",
    "    json_result = {}\n",
    "\n",
    "    for metric_function_name, metric_function in metric_functions.items():\n",
    "        json_result.setdefault('speech', {})[metric_function_name] = metric_function(clean_speech_signal, splitted_speech_signal)\n",
    "        if clean_noise_signal is not None and splitted_noise_signal is not None:\n",
    "            if len(clean_noise_signal) > len(splitted_noise_signal):\n",
    "                clean_noise_signal = clean_noise_signal[:len(splitted_noise_signal)]\n",
    "            else:\n",
    "                num_repeats = len(splitted_noise_signal) // len(clean_noise_signal) + 1\n",
    "                clean_noise_signal = np.tile(clean_noise_signal, num_repeats)[:len(splitted_noise_signal)]\n",
    "            json_result.setdefault('noise', {})[metric_function_name] = metric_function(clean_noise_signal, splitted_noise_signal)\n",
    "\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5121cd72-8bcf-41d2-8268-eca8c72447f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_avg_metrics(type_of_audio: Union['speech', 'noise'], metric_list):\n",
    "    # Define the columns and metrics\n",
    "    columns = ['sdr', 'r2', 'rmse', 'snr_level']\n",
    "    metrics = ['sdr', 'r2', 'rmse']\n",
    "    \n",
    "    # Create an empty DataFrame with the specified columns\n",
    "    method_metrics_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Iterate through the list of metrics for each track\n",
    "    data_to_append = []\n",
    "    \n",
    "    for track_metrics in metric_list:\n",
    "        for snr_level, speech_metrics in track_metrics.items():\n",
    "            speech_metrics = speech_metrics[type_of_audio]\n",
    "            \n",
    "            # Extract the desired metrics for speech and SNR level\n",
    "            metric_values = [float(speech_metrics.get(metric)) for metric in metrics] + [snr_level]\n",
    "            \n",
    "            # Add the metrics as a new row to the list\n",
    "            data_to_append.append(metric_values)\n",
    "    \n",
    "    # Concatenate the data to the DataFrame\n",
    "    method_metrics_df = pd.concat([method_metrics_df, pd.DataFrame(data_to_append, columns=columns)], ignore_index=True)\n",
    "    \n",
    "    mean_columns = ['avg_sdr', 'avg_r2', 'avg_rmse']\n",
    "    method_groupby_mean = method_metrics_df.groupby(by='snr_level').mean()\n",
    "    method_groupby_mean.columns = mean_columns\n",
    "    \n",
    "    median_columns = ['median_sdr', 'median_r2', 'median_rmse']\n",
    "    method_groupby_median = method_metrics_df.groupby(by='snr_level').median()\n",
    "    method_groupby_median.columns = median_columns\n",
    "    \n",
    "    method_metrics_agg_df = pd.concat([method_groupby_mean, method_groupby_median], axis=1)\n",
    "    \n",
    "    return method_metrics_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d018b8b-8738-47c0-b831-cf66212868ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_lower = -20\n",
    "snr_higher = 30\n",
    "snr_step = 10\n",
    "\n",
    "snd = SpeechNoiseDataset(f'{BASEPATH}/speech_data/', f'{BASEPATH}/noise_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba2232e-d41f-49a7-a594-5af1b00b4fae",
   "metadata": {},
   "source": [
    "## Experiment â„–1. ISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378413f2-ef6d-4c3a-874b-b7c17ff8701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica_separation(noised_speech, speech):\n",
    "    print(noised_speech.shape)\n",
    "    ica = FastICA(n_components=2)  # Assuming 2 components: speech and noise\n",
    "    separated_sources = ica.fit_transform(noised_speech)\n",
    "    print(separated_sources.shape)\n",
    "    noise = audio_normalization(separated_sources[:, 0])\n",
    "    voice = audio_normalization(separated_sources[:, 1])\n",
    "        \n",
    "    return noise, voice, calculate_r2_metric(voice, speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878aba3f-c3bb-4c5a-ae26-acbf6d872a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_metrics_list = []\n",
    "\n",
    "for idx_speech_track in trange(len(snd)):\n",
    "    speech, noise, sr = snd[idx_speech_track]\n",
    "    noised_speech_list = []\n",
    "    for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "        _, _, noised_speech = snr_mixer(speech, noise, current_snr)\n",
    "        noised_speech_list.append(noised_speech)\n",
    "    noised_speech_array = np.array(noised_speech_list)\n",
    "    splitted_noise, splitted_speech, r2_speech = ica_separation(noised_speech_array.T, speech)\n",
    "    break\n",
    "    while r2_speech < 0:\n",
    "        splitted_noise, splitted_speech, r2_speech = ica_separation(noised_speech_array.T, speech)\n",
    "    ica_metric_res = score_metrics(speech, splitted_speech, noise, splitted_noise)\n",
    "    ica_metrics_list.append(ica_metric_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184b451-d3a0-4502-961f-18ba4656109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_metrics_raw = pd.DataFrame([list_metric['speech'] for list_metric in ica_metrics_list])\n",
    "ica_metrics_raw.to_csv('./metrics/ica_metrics/raw_speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2d6a8-44a6-4b44-b368-73e463d60b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_metrics_raw = pd.DataFrame([list_metric['noise'] for list_metric in ica_metrics_list])\n",
    "ica_metrics_raw.to_csv('./metrics/ica_metrics/raw_noise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492db84-1259-4405-b66f-2e906e430743",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_part_list = ['speech', 'noise']\n",
    "\n",
    "isa_metrics_agg_df = pd.DataFrame(\n",
    "    columns=['avg_sdr', 'median_sdr', 'avg_r2', 'median_r2', 'mean_rmse', 'median_rmse'],\n",
    "    index=splitted_part_list\n",
    ")\n",
    "\n",
    "for idx, splitted_part in enumerate(splitted_part_list):\n",
    "    isa_metrics_part_df = pd.read_csv(f'./metrics/ica_metrics/raw_{splitted_part}.csv')\n",
    "    current_part_df = pd.Series({ \n",
    "        'avg_sdr': isa_metrics_part_df['sdr'].mean(),\n",
    "        'median_sdr': isa_metrics_part_df['sdr'].median(),\n",
    "        'avg_r2': isa_metrics_part_df['r2'].mean(),\n",
    "        'median_r2': isa_metrics_part_df['r2'].median(),\n",
    "        'mean_rmse': isa_metrics_part_df['rmse'].mean(),\n",
    "        'median_rmse': isa_metrics_part_df['rmse'].median(),\n",
    "    })\n",
    "    isa_metrics_agg_df.iloc[[idx]] = current_part_df\n",
    "\n",
    "isa_metrics_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bda1d7-7c8e-47ae-afbb-71e4febf3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa_metrics_agg_df.to_csv('./metrics/ica_metrics/grouped_speech_noise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad422dca-8961-4e2e-b828-e4eb4513e118",
   "metadata": {},
   "source": [
    "## Experiment â„–2. Substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce79c80-0d12-4ca6-9729-f3f53d31858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_lower = -20\n",
    "snr_higher = 30\n",
    "snr_step = 10\n",
    "\n",
    "snd = SpeechNoiseDataset(F'{BASEPATH}/speech_data/', f'{BASEPATH}/noise_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f858b-7f32-47f3-9b07-434822f11bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_subtraction(input_signal, noise_signal, signal_speech):\n",
    "    # Short-time Fourier transform (STFT) of the input signal\n",
    "    input_stft = librosa.stft(input_signal)\n",
    "    input_magnitude = np.abs(input_stft)\n",
    "    input_phase = np.angle(input_stft)\n",
    "\n",
    "    # STFT of the noise signal and compute the mean\n",
    "    noise_stft = librosa.stft(noise_signal)\n",
    "    noise_magnitude = np.abs(noise_stft)\n",
    "    noise_mean = np.mean(noise_magnitude, axis=1)\n",
    "\n",
    "    # Subtract noise spectral mean from input spectral magnitude\n",
    "    subtracted_magnitude = input_magnitude - noise_mean[:, np.newaxis]\n",
    "    \n",
    "    # Reconstruct the signal using the modified magnitude and original phase\n",
    "    reconstructed_stft = subtracted_magnitude * np.exp(1.0j * input_phase)\n",
    "    reconstructed_signal = librosa.istft(reconstructed_stft, length=len(input_signal))\n",
    "    return audio_normalization(reconstructed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d25ae7-fd27-45a3-8332-d7624cc06634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "substraction_metrics_list = []\n",
    "\n",
    "for idx_speech_track in trange(len(snd)):\n",
    "    speech, noise, sr = snd[idx_speech_track]\n",
    "    noised_speech_list = []\n",
    "    current_track_metrics = {}\n",
    "    for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "        _, _, noised_speech = snr_mixer(speech, noise, current_snr)\n",
    "        splitted_speech = spectral_subtraction(noised_speech, noise, speech)\n",
    "        current_snr_substraction_metrics = score_metrics(speech, splitted_speech)\n",
    "        current_track_metrics.update({current_snr: current_snr_substraction_metrics})\n",
    "    substraction_metrics_list.append(current_track_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86671173-4525-42f6-bc98-ec40141fdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_speech_track in trange(8015, len(snd)):\n",
    "    speech, noise, sr = snd[idx_speech_track]\n",
    "    noised_speech_list = []\n",
    "    current_track_metrics = {}\n",
    "    for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "        _, _, noised_speech = snr_mixer(speech, noise, current_snr)\n",
    "        splitted_speech = spectral_subtraction(noised_speech, noise, speech)\n",
    "        current_snr_substraction_metrics = score_metrics(speech, splitted_speech)\n",
    "        current_track_metrics.update({current_snr: current_snr_substraction_metrics})\n",
    "    substraction_metrics_list.append(current_track_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6d87e-9a3a-485f-a7f9-22d261cfb64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(substraction_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3f73a-c74d-4d2c-81d9-9096be4d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "    curr_snr_list = []\n",
    "    for elem_list in substraction_metrics_list:\n",
    "        curr_snr_list.append(\n",
    "            elem_list[current_snr]['speech']\n",
    "        )\n",
    "    # print(elem_list)\n",
    "    substraction_metrics_raw_speech_curr_snr = pd.DataFrame(curr_snr_list, columns=['sdr', 'r2', 'rmse'])\n",
    "    substraction_metrics_raw_speech_curr_snr.to_csv(f'./metrics/substraction_metrics/raw_speech_{current_snr}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819ab03-2d8c-45cd-afc4-1ab54ef1389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "substraction_metrics_agg_df = get_mean_avg_metrics('speech', substraction_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdaba9d-1d78-488a-88a9-a5821dedb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "substraction_metrics_agg_df.to_csv(f'./metrics/substraction_metrics/grouped_speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958608dc-42de-4a02-b848-02414214d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "substraction_metrics_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ccdcb-bef2-40df-bdac-900d4e46b108",
   "metadata": {},
   "source": [
    "## Experiment â„–3. Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843c921-81d1-4744-af4f-7d181eb9d4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitter_separation(files):\n",
    "    files_path = ' '.join(files)\n",
    "    splitting_command = f'spleeter separate -o output/ -p spleeter:2stems {files_path}'\n",
    "    subprocess.run(splitting_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa194f-e096-48f7-ae80-e08bd40de888",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_lower = -20\n",
    "snr_higher = 30\n",
    "snr_step = 10\n",
    "\n",
    "snd = SpeechNoiseDataset(F'{BASEPATH}/speech_data/', f'{BASEPATH}/noise_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5931541-baf1-4f29-b88b-57420fd76aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 16000\n",
    "end = len(snd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6e52f-09bb-40d1-83f8-a31f79400f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for idx_speech_track in trange(16290, end + 1):\n",
    "    speech, noise, sr = snd[idx_speech_track]\n",
    "    for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "        _, _, noised_speech = snr_mixer(speech, noise, current_snr)\n",
    "        filename = f'speech_{current_snr}'\n",
    "        filepath = f'/kaggle/working/noised_speech/{idx_speech_track}_{filename}.wav'\n",
    "        audiowrite(noised_speech, sr, filepath)\n",
    "        files.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b8a27-3098-4f8f-b938-5d510ccfdc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, ai_files in os.walk(f'{BASEPATH}/noised_speech'):\n",
    "    files = [f'{root}{file}' for file in sorted(ai_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c4986-c5bf-48c2-88ee-324b9f16bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(0, len(files) + 1, 50):\n",
    "    splitter_separation(files[i: i+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6863ca-0599-45a3-a08f-c158df283b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spleeter_metrics_list = []\n",
    "\n",
    "for root, dirs, files in os.walk('/kaggle/working/output/'):\n",
    "    for sub_dir in dirs:\n",
    "        idx_speech_track = int(sub_dir.split('_')[0])\n",
    "        current_snr = sub_dir.split('_')[-1]\n",
    "        path_to_track_dir = f'{root}{sub_dir}/'\n",
    "        splitted_speech, _ = audioread(f'/{path_to_track_dir}/vocals.wav', norm=False, sr=sr)\n",
    "        splitted_noise, _ = audioread(f'/{path_to_track_dir}/accompaniment.wav', norm=False, sr=sr)\n",
    "        speech, noise, sr = snd[idx_speech_track]\n",
    "        current_snr_spleeter_metrics = score_metrics(speech, splitted_speech[:len(speech)], noise, splitted_noise)\n",
    "        spleeter_metrics_list.append({current_snr: current_snr_spleeter_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b02fd-07c4-4872-a505-7c210e13f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spleeter_metrics_list[0], len(spleeter_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e20465-23e7-4946-9f4f-656829b30108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'/kaggle/working/spleeter_{start}_{end}.json', 'w') as fp:\n",
    "    json.dump(spleeter_metrics_list, fp, default=lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651d04f-76f9-414b-ab02-f3fb51dfdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r spleeter_16000_16289.zip /kaggle/working/spleeter_16000_16289.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb29610-4350-4ea9-92f9-6b301b08014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "spleeter_metrics_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(f'{BASEPATH}/metrics/spleeter_metrics/data'):\n",
    "    for file in files:\n",
    "        with open(f'{BASEPATH}/metrics/spleeter_metrics/data/{file}') as f:\n",
    "            spleeter_metrics_list.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68509d79-cfca-4518-8f4a-4788f79e9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_avg_metrics('speech', spleeter_metrics_list).to_csv(f'{BASEPATH}/metrics/spleeter_metrics/grouped_speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f6ea4a-a63e-49b9-8a20-1581bceae303",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_avg_metrics('noise', spleeter_metrics_list).to_csv(f'{BASEPATH}/metrics/spleeter_metrics/grouped_noise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d518fcc-3c0d-4c69-891e-09857cb25d8c",
   "metadata": {},
   "source": [
    "## Experiment â„–4. Demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bcdc4-475d-41af-a0a4-411af5a6a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install demucs -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2c568-3dde-44a3-b6c2-62d066778832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"hdemucs_mmi\"\n",
    "mp3 = False\n",
    "float32 = False  # output as float 32 wavs, unsused if 'mp3' is True.\n",
    "int24 = False \n",
    "two_stems = 'vocals'\n",
    "gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb96384-a40c-41ad-bfb7-34979986d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_process_streams(process: subprocess.Popen):\n",
    "    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n",
    "        assert stream is not None\n",
    "        if isinstance(stream, io.BufferedIOBase):\n",
    "            stream = stream.raw\n",
    "        return stream\n",
    "\n",
    "    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n",
    "    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n",
    "        p_stdout.fileno(): (p_stdout, sys.stdout),\n",
    "        p_stderr.fileno(): (p_stderr, sys.stderr),\n",
    "    }\n",
    "    fds = list(stream_by_fd.keys())\n",
    "\n",
    "    while fds:\n",
    "        # `select` syscall will wait until one of the file descriptors has content.\n",
    "        ready, _, _ = select.select(fds, [], [])\n",
    "        for fd in ready:\n",
    "            p_stream, std = stream_by_fd[fd]\n",
    "            raw_buf = p_stream.read(2 ** 16)\n",
    "            if not raw_buf:\n",
    "                fds.remove(fd)\n",
    "                continue\n",
    "            buf = raw_buf.decode()\n",
    "            std.write(buf)\n",
    "            std.flush()\n",
    "\n",
    "def separate(noised_speech, output_folder, sr, snr):\n",
    "    filename = f'speech_{snr}'\n",
    "    audiowrite(noised_speech, sr, f'/kaggle/working/{filename}.wav')\n",
    "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(output_folder), \"-n\", model]\n",
    "    if mp3:\n",
    "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
    "    if float32:\n",
    "        cmd += [\"--float32\"]\n",
    "    if int24:\n",
    "        cmd += [\"--int24\"]\n",
    "    if two_stems is not None:\n",
    "        cmd += [f\"--two-stems={two_stems}\"]\n",
    "    if gpu:\n",
    "        cmd += [\"-d\", \"cuda\", \"--segment\", \"176\", '-j', '2']\n",
    "    cmd += ['tracks', f'{filename}.wav']\n",
    "\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    copy_process_streams(p)\n",
    "    p.wait()\n",
    "    if p.returncode != 0:\n",
    "        print(\"Command failed, something went wrong.\")\n",
    "\n",
    "    speech, sp_sr = audioread(f'/kaggle/working/{output_folder}/{model}/{filename}/vocals.wav', norm=False, sr=sr)\n",
    "    noise, _ = audioread(f'/kaggle/working/{output_folder}/{model}/{filename}/no_vocals.wav', norm=False, sr=sr)\n",
    "\n",
    "    cmd_delete_file = f'rm /kaggle/working/{filename}.wav'\n",
    "    subprocess.run(cmd_delete_file, shell=True)\n",
    "    \n",
    "    return speech, noise\n",
    "\n",
    "\n",
    "def separate_new(filenames, output_folder):\n",
    "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(output_folder), \"-n\", model]\n",
    "    if mp3:\n",
    "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
    "    if float32:\n",
    "        cmd += [\"--float32\"]\n",
    "    if int24:\n",
    "        cmd += [\"--int24\"]\n",
    "    if two_stems is not None:\n",
    "        cmd += [f\"--two-stems={two_stems}\"]\n",
    "    if gpu:\n",
    "        cmd += [\"-d\", \"cuda\", \"--segment\", \"352\", '-j', '5']\n",
    "    cmd += list(map(lambda x: f\"{x}\", filenames))\n",
    "    \n",
    "\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    copy_process_streams(p)\n",
    "    p.wait()\n",
    "    if p.returncode != 0:\n",
    "        print(\"Command failed, something went wrong.\")\n",
    "\n",
    "    cmd_delete_file = f'rm -r /kaggle/working/noised_speech/'\n",
    "    subprocess.run(cmd_delete_file, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df706813-f4d3-46a1-9067-34dbefe9a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_lower = -20\n",
    "snr_higher = 30\n",
    "snr_step = 10\n",
    "sample_rate = 41000\n",
    "\n",
    "snd = SpeechNoiseDataset(f'{BASEPATH}/speech-data/speech_data/', f'{BASEPATH}/noise-data-audio/noise_data/', sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91755d41-398c-4907-b701-fb80b6f9f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e556701-64f7-4f9f-9668-6239cd367c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for idx_speech_track in trange(start, end):\n",
    "    speech, noise, sr = snd[idx_speech_track]\n",
    "    current_track_metrics = {}\n",
    "    for current_snr in np.arange(snr_lower, snr_higher, snr_step):\n",
    "        _, _, noised_speech = snr_mixer(speech, noise, current_snr)\n",
    "        filename = f'speech_{current_snr}'\n",
    "        filepath = f'/kaggle/working/noised_speech/{idx_speech_track}_{filename}.wav'\n",
    "        audiowrite(noised_speech, sr, filepath)\n",
    "        files.append(filepath)\n",
    "separate_new(files, 'demucs_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ca06d-09dd-49f9-a770-83e908c44cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "demucs_metrics_list = []\n",
    "\n",
    "for root, dirs, files in os.walk('/kaggle/working/demucs_new/hdemucs_mmi/'):\n",
    "    for sub_dir in dirs:\n",
    "        idx_speech_track = int(sub_dir.split('_')[0])\n",
    "        current_snr = sub_dir.split('_')[-1]\n",
    "        path_to_track_dir = f'{root}{sub_dir}/'\n",
    "        splitted_speech, _ = audioread(f'/{path_to_track_dir}/vocals.wav', norm=False, sr=sr)\n",
    "        splitted_noise, _ = audioread(f'/{path_to_track_dir}/no_vocals.wav', norm=False, sr=sr)\n",
    "        speech, noise, sr = snd[idx_speech_track]\n",
    "        current_snr_demucs_metrics = score_metrics(speech, splitted_speech[:len(speech)], noise, splitted_noise)\n",
    "        demucs_metrics_list.append({current_snr: current_snr_demucs_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a1cfe-e125-48db-9ef6-54dc0fab68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "demucs_metrics_list[:4], len(demucs_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f210ed8-25e4-4042-9ea7-3f39ffc97296",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r demucs_0_1000.zip /kaggle/working/demucs_0_1000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6bd1e-084d-4074-9e0e-f0b62772bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "demucs_metrics_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(f'{BASEPATH}/metrics/demucs_metrics/data'):\n",
    "    for file in files:\n",
    "        with open(f'{BASEPATH}/metrics/demucs_metrics/data/{file}') as f:\n",
    "            spleeter_metrics_list.extend(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a37aaf-e0d2-41de-aab2-e8fd62ec98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_avg_metrics('speech', demucs_metrics_list).to_csv(f'{BASEPATH}/metrics/demucs_metrics/grouped_speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a200887-8b2f-4c2c-84bd-1a1662353f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_avg_metrics('noise', demucs_metrics_list).to_csv(f'{BASEPATH}/metrics/demucs_metrics/grouped_noise.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
