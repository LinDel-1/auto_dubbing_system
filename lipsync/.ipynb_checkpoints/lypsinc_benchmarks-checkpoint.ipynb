{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff10f08-2c1a-49af-a671-25ab4098f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lindel/diploma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc728-bb33-4352-9a06-c1167fcba972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install whisperx sacremoses TTS moviepy python_speech_features scenedetect --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e6408-c7b7-454e-9e85-78005a896562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a9f4f-cccb-4e00-9d4c-9e361c661303",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/zabique/Wav2Lip\n",
    "\n",
    "#download the pretrained model\n",
    "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O 'Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
    "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
    "\n",
    "# !pip uninstall tensorflow tensorflow-gpu\n",
    "!cd Wav2Lip && pip install -r requirements.txt\n",
    "\n",
    "#download pretrained model for face detection\n",
    "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
    "\n",
    "!pip install -q youtube-dl\n",
    "!pip install ffmpeg-python\n",
    "!pip install librosa==0.9.1\n",
    "\n",
    "#this code for recording audio\n",
    "\"\"\"\n",
    "To write this piece of code I took inspiration/code from a lot of places.\n",
    "It was late night, so I'm not sure how much I created or just copied o.O\n",
    "Here are some of the possible references:\n",
    "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
    "https://stackoverflow.com/a/18650249\n",
    "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
    "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
    "https://stackoverflow.com/a/49019356\n",
    "\"\"\"\n",
    "from IPython.display import HTML, Audio\n",
    "# from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acad57bd-8413-4bbd-b990-8eb28e06829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diff2lip'...\n",
      "remote: Enumerating objects: 84, done.\u001b[K\n",
      "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 84 (delta 11), reused 68 (delta 5), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (84/84), 15.73 MiB | 810.00 KiB/s, done.\n",
      "Resolving deltas: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/soumik-kanad/diff2lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83665a23-5a30-4ad5-a147-8bc9bf89b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/joonson/syncnet_python.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f7526-75eb-4813-8af9-7a6687f58605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import wave\n",
    "import moviepy.editor as m_ed\n",
    "from typing import Callable, Union\n",
    "from IPython.display import Audio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "from tqdm import trange\n",
    "\n",
    "from utils.audio_funcs import audioread, audiowrite, snr_mixer, audio_normalization, align_audio\n",
    "from basemodel.model import BaseAutoDubbingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca33958-b07c-4962-9741-5396c84a2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/lipsync-output-video /kaggle/working/lipsync-output-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26845ea-acbb-44ab-a95d-570c16272cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Wav2Lip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce48b8-f74d-457f-9a3a-d22e79fc79fd",
   "metadata": {},
   "source": [
    "## Wav2Lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09908fea-2010-4d86-90a9-7d35287c875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_path = '/kaggle/input/lipsync-dataset'\n",
    "base_video_output_path = '/kaggle/working/lipsync-output-video'\n",
    "base_audio_output_path = '/kaggle/working/lipsync-output-audio'\n",
    "dubbing_model = BaseAutoDubbingModel()\n",
    "\n",
    "for video_prefix in trange(1, 10):\n",
    "    input_video_path = f\"{base_input_path}/{video_prefix}.mp4\"\n",
    "    output_video_path = f\"{base_video_output_path}/{video_prefix}_trans.mp4\"\n",
    "    input_audio_path = f\"{base_audio_output_path}/{video_prefix}.wav\"\n",
    "    output_audio_path = f\"{base_audio_output_path}/{video_prefix}_trans.wav\"\n",
    "    output_mod_audio_path = f\"{base_audio_output_path}/{video_prefix}_trans_mod.wav\"\n",
    "    \n",
    "    dubbing_model.get_audio_from_video(input_video_path, input_audio_path)\n",
    "    input_text_objs = dubbing_model.get_text_from_voice(input_audio_path)\n",
    "    output_text_objs = dubbing_model.translate(input_text_objs)\n",
    "    dubbing_model.text_to_speech(output_text_objs, input_audio_path, output_audio_path, output_mod_audio_path)\n",
    "    \n",
    "    subprocess.run([\n",
    "        \"python\",\n",
    "        \"inference.py\",\n",
    "        \"--checkpoint_path\",\n",
    "        \"checkpoints/wav2lip_gan.pth\",\n",
    "        \"--face\",\n",
    "        input_video_path,\n",
    "        \"--audio\",\n",
    "        output_mod_audio_path,\n",
    "        \"--outfile\",\n",
    "        output_video_path\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1186fb-a6e2-4d31-bf80-623c7628db3e",
   "metadata": {},
   "source": [
    "## Dif2Lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bbdfe-c3e0-4070-afac-8d4d3acb1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables to allow running as root\n",
    "os.environ['OMPI_ALLOW_RUN_AS_ROOT'] = '1'\n",
    "os.environ['OMPI_ALLOW_RUN_AS_ROOT_CONFIRM'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363536a6-345a-4c5b-b56c-4da9531fe622",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libopenmpi-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefff19f-9cf7-4c28-a615-7fb454caa311",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install blobfile mpi4py gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca7e69-8d90-465a-94e6-b65bfec1226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd diff2lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25d7ff-0ced-4c2b-87c6-7068922dae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir guided_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3657fea-8406-4390-8bdd-f91458abcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp guided-diffusion/guided_diffusion/* guided_diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d4702-3867-4f63-97c0-2cf25f3b23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3135489-a88f-418b-a5f1-29dbd67b4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown \"https://drive.google.com/uc?id=15vMcyPtFDEttNwelP3IouwsMpnccTqit\" -O checkpoints/checkpoint.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6c279-ee42-4793-b011-421d02d3eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x /kaggle/working/diff2lip/scripts/inference_single_video_my.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49f7cc-a482-4481-86f4-bc1ec2bcbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(3, 4):\n",
    "    with open(\"/kaggle/working/diff2lip/scripts/inference_single_video.sh\") as f:\n",
    "        file_read = f.read()\n",
    "        file_read = file_read.replace(\"NUM_GPUS=1\", \"NUM_GPUS=2\") \\\n",
    "        .replace(\"path/to/video.mp4\", f\"/kaggle/input/lipsync-dataset/{i}.mp4\") \\\n",
    "        .replace(\"path/to/audio.mp4\", f\"/kaggle/working/lipsync-output-audio/{i}_trans_mod.wav\") \\\n",
    "        .replace(\"path/to/output.mp4\", f\"/kaggle/working/lipsync-output-video/{i}.mp4\") \\\n",
    "        .replace(\"path/to/model.pt\", \"/kaggle/working/diff2lip/checkpoints/checkpoint.pt\")\n",
    "        \n",
    "    with open(\"/kaggle/working/diff2lip/scripts/inference_single_video_my.sh\", \"w\") as f:\n",
    "        f.write(file_read)\n",
    "        \n",
    "    !scripts/inference_single_video_my.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececa14f-d59c-4f16-8eb4-580bc685623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd syncnet_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bb31e-0390-4ce7-82e1-b4b7e00402b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh download_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4f324-5bea-4a88-8c30-c41780e19460",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Wav2Lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771d5db-9a06-45ab-88f9-bac5a09f6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd evaluation/scores_LSE/\n",
    "%cp *.py /kaggle/working/syncnet_python/\n",
    "%cp *.sh /kaggle/working/syncnet_python/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7715b2c-ffeb-4a78-8566-a90a2d0f7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd syncnet_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c6bdb-da79-434f-b0b7-8533da8aad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/kaggle/working/syncnet_python/detectors/s3fd/box_utils.py\", \"r+\") as f:\n",
    "    file_data = f.read()\n",
    "    file_data = file_data.replace(\"np.int\", \"np.int32\")\n",
    "with open(\"/kaggle/working/syncnet_python/detectors/s3fd/box_utils.py\", \"w\") as f:\n",
    "    f.write(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0f08c-99c8-4d02-8089-4c7376835eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/translated-dif2lip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d2045-143c-4c9f-a51d-896b9c536d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r /kaggle/working/translated-dif2lip/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2dc45-a34f-43c9-a66a-c2f3eeb5224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /kaggle/input/translated-dif2lip/* /kaggle/working/translated-dif2lip/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f16792-bbaa-470e-b9d9-5f67be35cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh calculate_scores_real_videos.sh /kaggle/working/translated-dif2lip/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bee9ed-110f-4b63-a5ce-dee43a878252",
   "metadata": {},
   "source": [
    "## Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc94f1a-47f1-40c6-9e2d-82df2838bcac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review_embeddings",
   "language": "python",
   "name": "review_embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
